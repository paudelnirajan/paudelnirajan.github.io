<!DOCTYPE html>
<html lang="en" data-theme="dark">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Nirajan Paudel | ML Engineer & Researcher</title>
    <meta name="description"
        content="Nirajan Paudel - MS Computer Science at CU Boulder, specializing in AI/ML, Cloud Infrastructure, and NLP">
    <meta name="keywords" content="Nirajan Paudel, Computer Science, AI, Machine Learning, NLP, Cloud, DevOps">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link
        href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500;600;700&family=Outfit:wght@300;400;500;600;700&display=swap"
        rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css">
    <link rel="stylesheet" href="styles.css">
</head>

<body>
    <!-- Animated Background -->
    <canvas id="particles-canvas"></canvas>

    <div class="container">
        <!-- Header / Hero Section -->
        <header class="hero" id="home">
            <div class="hero-content">
                <div class="hero-text">
                    <p class="greeting">
                        <span class="code-accent">&lt;</span>hello world<span class="code-accent">/&gt;</span>
                    </p>
                    <h1 class="hero-name">
                        I'm <span class="highlight">Nirajan Paudel</span>
                    </h1>
                    <p class="hero-title">
                        <span class="typewriter">ML Engineer</span>
                        <span class="cursor">|</span>
                    </p>
                    <p class="hero-subtitle">
                        M.S. Computer Science @ CU Boulder<br>
                        Building intelligent systems with AI, Cloud & NLP
                    </p>
                    <div class="hero-cta">
                        <a href="#projects" class="btn btn-primary">View Projects</a>
                        <a href="#about" class="btn btn-outline">About Me</a>
                    </div>
                    <div class="social-links">
                        <a href="mailto:nirajan.paudel@colorado.edu" aria-label="Email" class="social-link">
                            <i class="fas fa-envelope"></i>
                        </a>
                        <a href="https://www.linkedin.com/in/nirajanpaudel17/" target="_blank" aria-label="LinkedIn"
                            class="social-link">
                            <i class="fab fa-linkedin"></i>
                        </a>
                        <a href="https://github.com/paudelnirajan" target="_blank" aria-label="GitHub"
                            class="social-link">
                            <i class="fab fa-github"></i>
                        </a>
                        <a href="https://x.com/paudelnirajan17" target="_blank" aria-label="Twitter"
                            class="social-link">
                            <i class="fab fa-twitter"></i>
                        </a>
                    </div>
                </div>
                <div class="hero-image">
                    <div class="image-wrapper">
                        <img src="photo_for_website.jpg" alt="Nirajan Paudel" class="profile-photo">
                        <div class="image-border"></div>
                    </div>
                </div>
            </div>
            <div class="scroll-indicator">
                <span>scroll</span>
                <i class="fas fa-chevron-down"></i>
            </div>
        </header>

        <!-- Navigation -->
        <nav class="nav" id="nav">
            <div class="nav-container">
                <a href="#home" class="nav-logo">
                    <span class="code-accent">&lt;</span>NP<span class="code-accent">/&gt;</span>
                </a>
                <ul class="nav-links">
                    <li><a href="#about" class="nav-link">About</a></li>
                    <li><a href="#projects" class="nav-link">Projects</a></li>
                    <li><a href="#skills" class="nav-link">Skills</a></li>
                    <li><a href="#publications" class="nav-link">Publications</a></li>
                    <li><a href="#blog" class="nav-link">Blog</a></li>
                    <li><a href="Nirajan_Paudel.pdf" class="nav-link btn-nav" download>Resume</a></li>
                </ul>

                <!-- Theme Toggle -->
                <button class="theme-toggle" id="theme-toggle" aria-label="Toggle theme">
                    <i class="fas fa-moon" id="theme-icon"></i>
                </button>

                <button class="nav-toggle" id="nav-toggle" aria-label="Toggle menu">
                    <span></span>
                    <span></span>
                    <span></span>
                </button>
            </div>
        </nav>

        <!-- About Section -->
        <section id="about" class="section">
            <div class="section-header">
                <h2 class="section-title">
                    <span class="code-accent">//</span> About Me
                </h2>
                <div class="section-line"></div>
            </div>
            <div class="about-content">
                <div class="about-text">
                    <p>
                        I'm a <strong>Master's student in Computer Science</strong> at the University of Colorado
                        Boulder, passionate about building intelligent systems that solve real-world problems.
                    </p>
                    <p>
                        My journey spans from developing <strong>AI-driven chatbots</strong> to teaching programming
                        fundamentals as a teaching assistant. I thrive at the intersection of <strong>Machine Learning,
                            Cloud Infrastructure, and NLP</strong>.
                    </p>
                    <p class="about-quote">
                        <i class="fas fa-quote-left"></i>
                        Will humans be able to preserve their culture and language in AI models that persist longer than
                        humans themselves?
                    </p>
                </div>
                <div class="about-interests">
                    <h3>Research Focus</h3>
                    <ul class="interest-list">
                        <li><i class="fas fa-brain"></i> Multilingual NLP & Low-resource Languages</li>
                        <li><i class="fas fa-language"></i> Cross-lingual Transfer Learning</li>
                        <li><i class="fas fa-robot"></i> LLM Adaptation & Fine-tuning</li>
                        <li><i class="fas fa-eye"></i> Computer Vision & Autonomous Systems</li>
                    </ul>
                </div>
            </div>
        </section>

        <!-- Projects Section -->
        <section id="projects" class="section">
            <div class="section-header">
                <h2 class="section-title">
                    <span class="code-accent">//</span> Projects
                </h2>
                <div class="section-line"></div>
            </div>

            <!-- Project Filters -->
            <div class="project-filters">
                <button class="filter-btn" data-filter="all">All</button>
                <button class="filter-btn active" data-filter="featured">Featured</button>
                <button class="filter-btn" data-filter="cloud">Cloud & DevOps</button>
                <button class="filter-btn" data-filter="ai">AI & ML</button>
            </div>

            <div class="projects-grid">
                <!-- Featured Project 1: Tensor -->
                <article class="project-card featured" data-category="featured ai">
                    <div class="project-header">
                        <div class="project-icon">
                            <i class="fas fa-brain"></i>
                        </div>
                        <div class="project-links-top">
                            <a href="https://tensor-h3v4h351a-nirajans-projects-f6261255.vercel.app/" target="_blank" aria-label="Live Demo" id="tensor-demo-link">
                                <i class="fas fa-external-link-alt"></i>
                            </a>
                        </div>
                    </div>
                    <span class="project-badge">Featured</span>
                    <h3 class="project-title">Tensor: Agentic RAG Academic AI</h3>
                    <p class="project-description">
                        Advanced RAG conversational AI platform engineered for engineering students, solving fragmented
                        academic resource navigation by providing centralized access to past exam papers, syllabuses, and
                        technical notes with intelligent question answering.
                    </p>
                    <div class="project-tech">
                        <span>FastAPI</span>
                        <span>React</span>
                        <span>Pinecone</span>
                        <span>Redis</span>
                    </div>
                    <button class="project-expand" aria-label="Expand details">
                        <span>Details</span>
                        <i class="fas fa-arrow-right"></i>
                    </button>
                    <div class="project-details">
                        <h4>The Challenge</h4>
                        <p>Engineering students at the Institute of Engineering, Nepal struggle to navigate fragmented
                            academic resources—thousands of pages of legacy PDFs, multi-page syllabuses, and complex
                            technical notes. Traditional search tools fail when students ask year-specific or
                            chapter-specific questions (e.g., "Show me 8-mark numericals on Sorting from 2076") because
                            engineering documents contain both semantic meaning and rigid metadata.</p>

                        <h4>The Solution</h4>
                        <p>Tensor is an advanced Retrieval-Augmented Generation (RAG) conversational AI platform that
                            provides a centralized, intelligent interface capable of answering specific technical
                            questions, retrieving relevant past papers, and providing study guidance through a
                            Multi-Stage Agentic RAG pipeline.</p>

                        <h4>Challenge 1: Semantic Search in Highly Structured Technical Data</h4>
                        <p><strong>Problem:</strong> Traditional search tools fail with year-specific or chapter-specific
                            queries because engineering documents contain both semantic meaning and rigid metadata.</p>
                        <p><strong>Solution:</strong> Implemented a Hybrid Query Architecture that combines:</p>
                        <ul>
                            <li><strong>AI Metadata Extraction (Smart Filtering):</strong> Using GPT-4o-mini to
                                dynamically extract filters (year, subject, chapter, marks) from natural language queries
                            </li>
                            <li><strong>Vector Search:</strong> Using OpenAI/Gemini Embeddings and Pinecone Serverless for
                                high-precision semantic retrieval</li>
                            <li><strong>Metadata Filtering:</strong> Engineered a layer that converts natural language into
                                complex Pinecone filter objects, ensuring zero-noise results for year-specific queries
                            </li>
                            <li><strong>Intent Routing:</strong> An LLM-based router classifies queries into four
                                categories: Structured (Syllabus/Marks), Semantic (Explanations), Past Question (Historical
                                papers), or Hybrid</li>
                        </ul>

                        <h4>Challenge 2: Precision in Complex Engineering Papers</h4>
                        <p><strong>Problem:</strong> Engineering questions often involve diagrams, formulas, and specific
                            marking schemes that basic PDF parsers fail to capture.</p>
                        <p><strong>Solution:</strong> Developed a specialized Ingestion Pipeline:</p>
                        <ul>
                            <li><strong>Multimodal PDF Parsing:</strong> Used LlamaParse for high-fidelity parsing to
                                preserve diagrams, tables, mathematical notations, and structured content</li>
                            <li><strong>Question-Boundary Aware Chunking:</strong> Instead of arbitrary character splits,
                                the system detects question boundaries (e.g., "1a", "2b") to ensure context remains intact
                                and respects document hierarchy (Chapters > Sections > Paragraphs)</li>
                            <li><strong>Two-Stage Reranking:</strong> Implemented a retrieval pool of 50 candidates,
                                followed by a Reranker Service using Cross-Encoder Model (ms-marco-MiniLM-L-6-v2) to
                                narrow down the top 10 most relevant chunks for the LLM</li>
                            <li><strong>Automated Syllabus Mapping:</strong> Built a custom curriculum engine that maps
                                10+ engineering programs (BCT, BCE, BEL, etc.) across 8 semesters, ensuring data is tagged
                                with precise metadata (Program, Year, Semester, Subject Code)</li>
                            <li><strong>Markdown Cleanup Pipeline:</strong> Custom pipeline that strips non-semantic
                                headers/footers and identifies Page Context to inject metadata into every chunk, allowing
                                the AI to cite specific pages in responses</li>
                        </ul>

                        <h4>Challenge 3: Cost and Latency in LLM Workflows</h4>
                        <p><strong>Problem:</strong> Frequent RAG lookups and LLM calls can lead to high latency (>10s)
                            and ballooning API costs.</p>
                        <p><strong>Solution:</strong> Built a Multi-Layer Distributed Caching System using Async Redis
                            (Upstash):</p>
                        <ul>
                            <li><strong>Result Caching:</strong> Immediate response for identical queries, delivering
                                instant answers for frequent student queries</li>
                            <li><strong>Intent/Metadata Caching:</strong> Caching the AI-extracted filters themselves,
                                preventing re-classifying similar questions and reducing LLM "thought" time</li>
                            <li><strong>Embedding Cache:</strong> Saves 100% of LLM costs for repeated query vectors</li>
                            <li><strong>Streaming Architecture:</strong> Implemented Server-Sent Events (SSE) for
                                real-time response streaming</li>
                        </ul>
                        <p><strong>Outcome:</strong> Achieved a 60%+ cache hit rate, reducing total query costs by
                            approximately $0.001 per query and cutting P95 response times to under 3 seconds.</p>

                        <h4>Engineering Challenges & Solutions</h4>
                        <ul>
                            <li><strong>Memory Constraints on Free-Tier Hosting:</strong> Loading the Cross-Encoder
                                model into memory required ~400MB of RAM, causing the 512MB Render server to experience
                                Out-Of-Memory crashes. Solution: Implemented Feature Toggling and Lazy Loading with a
                                configuration-driven switch that detects the hosting environment and toggles the heavy ML
                                model off in favor of optimized similarity search when resources are low, maintaining
                                99.9% uptime</li>
                            <li><strong>Python 3.11 Environment Stability:</strong> Modern f-string features caused
                                syntax errors in certain server-side environments. Solution: Performed a codebase-wide
                                refactor of the formatting logic, replacing complex f-strings with robust string
                                concatenation and pathlib for file routing, ensuring 100% environmental portability</li>
                        </ul>

                        <h4>Key Metrics & Impact</h4>
                        <ul>
                            <li><strong>Data Scale:</strong> Ingested and indexed 25+ comprehensive engineering past
                                papers (Mathematics, C Programming) with dynamic metadata tagging</li>
                            <li><strong>Performance:</strong> Optimized response latency to under 3 seconds (P95) through
                                streaming architecture and Redis caching, with less than 200ms TTFT (Time To First Token)
                            </li>
                            <li><strong>Efficiency:</strong> Reduced OpenAI/Gemini API dependency by establishing a 60%+
                                cache hit rate for common student queries, reducing LLM API overhead by 70%</li>
                            <li><strong>Scalability:</strong> Designed a system capable of handling 100,000+ vectors using
                                Pinecone Serverless architecture</li>
                            <li><strong>Precision:</strong> Achieved 85%+ query accuracy through dual-stage "Retrieve &
                                Rerank" pipeline, with reranking layer improving Top-1 retrieval accuracy by 40% compared
                                to standard vector search</li>
                            <li><strong>Architecture:</strong> Managed 7+ micro-services/mixins in the backend (RAG,
                                Reranker, Intent Router, Multi-Doc Chunker) to ensure modularity</li>
                        </ul>

                        <h4>Tech Stack</h4>
                        <p><strong>Backend:</strong> Python, FastAPI, SQLAlchemy, Pydantic</p>
                        <p><strong>Frontend:</strong> React, Vite, Tailwind CSS, Vercel AI SDK (for streaming)</p>
                        <p><strong>AI/ML:</strong> OpenAI (GPT-4o/mini), Gemini (Embeddings), Pinecone (Vector DB),
                            LlamaParse, Sentence-Transformers</p>
                        <p><strong>Infrastructure:</strong> Redis (Async/Upstash Caching), Vercel (Frontend Deployment),
                            Railway/Local (Backend), GitHub Actions (CI/CD)</p>
                        <p><strong>Integrations:</strong> Multi-LLM provider support (Groq, Gemini, OpenAI)</p>

                        <h4>Skills Demonstrated</h4>
                        <p>This project demonstrates expertise in RAG systems, vector databases, distributed caching
                            strategies, production ML deployment, and building scalable AI architectures that solve
                            real-world problems in academic settings.</p>
                    </div>
                </article>

                <!-- Featured Project 2: Zenco -->
                <article class="project-card featured" data-category="featured ai">
                    <div class="project-header">
                        <div class="project-icon">
                            <i class="fas fa-code"></i>
                        </div>
                        <div class="project-links-top">
                            <a href="https://github.com/paudelnirajan/autodoc" target="_blank" aria-label="GitHub">
                                <i class="fab fa-github"></i>
                            </a>
                            <a href="https://pypi.org/project/zenco/" target="_blank" aria-label="PyPI">
                                <i class="fas fa-external-link-alt"></i>
                            </a>
                            <a href="https://github.com/paudelnirajan/zenco-vscode-extension" target="_blank" aria-label="VS Code Extension">
                                <i class="fas fa-code"></i>
                            </a>
                        </div>
                    </div>
                    <span class="project-badge">Featured</span>
                    <h3 class="project-title">Zenco: AI Code Analysis Platform</h3>
                    <p class="project-description">
                        Open-source CLI tool leveraging LLMs to automate code documentation, refactoring, and quality
                        enhancement across 5 languages. Reduces dev time by 20-30% and API costs by 30-50%.
                    </p>
                    <div class="project-tech">
                        <span>Python</span>
                        <span>Tree-sitter</span>
                        <span>LLM APIs</span>
                        <span>CI/CD</span>
                    </div>
                    <button class="project-expand" aria-label="Expand details">
                        <span>Details</span>
                        <i class="fas fa-arrow-right"></i>
                    </button>
                    <div class="project-details">
                        <h4>The Challenge</h4>
                        <p>Software developers spend 20-30% of their time on repetitive tasks like writing docstrings,
                            adding type hints, and identifying dead code. These essential maintenance tasks are
                            time-consuming and expensive when using LLM APIs inefficiently on large codebases.</p>

                        <h4>The Solution</h4>
                        <p>Zenco provides an intelligent code analysis pipeline with a breakthrough execution priority
                            system that processes dead code detection first, then skips dead code in subsequent analysis
                            stages—achieving 30-50% reduction in LLM API calls and processing time.</p>

                        <h4>Technical Architecture</h4>
                        <ul>
                            <li><strong>Multi-Language Support:</strong> Implemented Tree-sitter for universal parsing
                                across Python, JavaScript, Java, C++, and Go with language-specific documentation
                                formatters</li>
                            <li><strong>Modular Design:</strong> Refactored monolithic 2,057-line codebase into 4
                                independent processors (DeadCodeProcessor, DocstringProcessor, TypeHintProcessor,
                                MagicNumberProcessor), reducing core module to 603 lines—a 70% reduction</li>
                            <li><strong>Design Patterns:</strong> Applied Strategy pattern for pluggable LLM providers,
                                Factory pattern for dynamic instantiation, Visitor pattern for AST traversal, and
                                Adapter pattern for unified LLM interfaces</li>
                            <li><strong>LLM Integration:</strong> Unified API interface supporting Groq, OpenAI,
                                Anthropic, and Google Gemini with intelligent error handling and fallback strategies
                            </li>
                        </ul>

                        <h4>DevOps & Quality Assurance</h4>
                        <ul>
                            <li><strong>Comprehensive CI/CD:</strong> GitHub Actions pipeline with matrix testing across
                                3 operating systems (Ubuntu, macOS, Windows) and 4 Python versions (3.9-3.12)—12
                                platform combinations</li>
                            <li><strong>Test Coverage:</strong> Achieved 95.5% test pass rate with unit and integration
                                tests, ensuring production reliability</li>
                            <li><strong>Package Distribution:</strong> Published on PyPI with automated versioning and
                                release management</li>
                            <li><strong>Developer Experience:</strong> Rich terminal UI with color-coded output,
                                interactive configuration wizard, and comprehensive documentation</li>
                        </ul>

                        <h4>Performance & Impact</h4>
                        <ul>
                            <li><strong>Cost Efficiency:</strong> 30-50% reduction in LLM API costs through dead code
                                optimization</li>
                            <li><strong>Code Quality:</strong> 95.5% test coverage with production-ready reliability
                            </li>
                            <li><strong>Maintainability:</strong> 70% reduction in core module complexity</li>
                            <li><strong>Scalability:</strong> Processes codebases of any size with configurable batch
                                processing</li>
                        </ul>

                        <h4>VS Code Extension</h4>
                        <p>Developed an official Visual Studio Code extension that brings Zenco's AI-powered code analysis
                            directly into the IDE, providing seamless integration for developers.</p>
                        <ul>
                            <li><strong>IDE Integration:</strong> Built a TypeScript-based VS Code extension that
                                integrates the Zenco CLI tool directly into the editor workflow, eliminating the need to
                                switch between terminal and IDE</li>
                            <li><strong>Core Features:</strong> Provides all CLI functionality including file refactoring,
                                automatic docstring generation (Google, NumPy, RST styles), type hint addition, magic
                                number detection, and dead code removal</li>
                            <li><strong>User Experience:</strong> Implemented a diff view for side-by-side comparison
                                of proposed changes before applying, giving developers full control over code
                                modifications</li>
                            <li><strong>Automatic CLI Management:</strong> Engineered automatic installation and
                                management of the Zenco CLI tool, with smart path resolution across Windows, macOS, and
                                Linux platforms</li>
                            <li><strong>Multi-Provider Support:</strong> Configured extension settings for seamless
                                integration with Groq, OpenAI, Anthropic, and Google Gemini LLM providers</li>
                            <li><strong>Developer Workflow:</strong> Streamlined access through status bar integration,
                                allowing developers to trigger code analysis with a single click without leaving the
                                editor</li>
                            <li><strong>Cross-Platform Compatibility:</strong> Ensured robust error handling and
                                cross-platform compatibility for CLI detection and execution</li>
                        </ul>

                        <h4>Skills Demonstrated</h4>
                        <p><strong>Software Engineering:</strong> Advanced Python, TypeScript, OOP, SOLID principles,
                            design patterns, API integration, async programming</p>
                        <p><strong>AI/ML:</strong> LLM API integration, prompt engineering, context-aware systems, cost
                            optimization</p>
                        <p><strong>DevOps:</strong> CI/CD pipelines, GitHub Actions, multi-platform testing, PyPI
                            distribution</p>
                        <p><strong>IDE Development:</strong> VS Code Extension API, TypeScript, cross-platform CLI
                            integration, developer tooling</p>
                    </div>
                </article>

                <!-- Featured Project 2: K8s vs Lambda -->
                <article class="project-card featured" data-category="featured cloud">
                    <div class="project-header">
                        <div class="project-icon">
                            <i class="fas fa-cloud"></i>
                        </div>
                        <div class="project-links-top">
                            <a href="https://github.com/paudelnirajan/k8s-vs-lambda-nlp-benchmark.git" target="_blank"
                                aria-label="GitHub">
                                <i class="fab fa-github"></i>
                            </a>
                        </div>
                    </div>
                    <span class="project-badge">Featured</span>
                    <h3 class="project-title">Serverless vs Kubernetes Benchmark</h3>
                    <p class="project-description">
                        Production-grade infrastructure comparing AWS Lambda and EKS for DistilBERT sentiment analysis.
                        Full IaC, CI/CD, and observability.
                    </p>
                    <div class="project-tech">
                        <span>AWS</span>
                        <span>Terraform</span>
                        <span>Kubernetes</span>
                        <span>FastAPI</span>
                    </div>
                    <button class="project-expand" aria-label="Expand details">
                        <span>Details</span>
                        <i class="fas fa-arrow-right"></i>
                    </button>
                    <div class="project-details">
                        <h4>The Challenge</h4>
                        <p>Compare serverless and containerized deployments for ML inference, analyzing cold start
                            behavior, latency, scalability, and cost trade-offs. Key technical constraint: DistilBERT
                            model load time (~60s) exceeds API Gateway's 29-second timeout limit.</p>

                        <h4>Solution Architecture</h4>
                        <ul>
                            <li><strong>AWS Lambda (Serverless):</strong> Container-based Lambda function (3008 MB RAM)
                                with API Gateway REST API integration and pay-per-request pricing</li>
                            <li><strong>Kubernetes (EKS):</strong> EKS cluster with managed node groups, 2-replica
                                deployment for high availability, and Classic Load Balancer for external access</li>
                            <li><strong>FastAPI Backend:</strong> Request router directing traffic to Lambda or
                                Kubernetes with exponential backoff retry for Lambda cold starts and Prometheus metrics
                            </li>
                            <li><strong>Streamlit Dashboard:</strong> Real-time side-by-side comparison with Locust load
                                testing integration and AI-powered analysis using Groq API (Llama 3)</li>
                        </ul>

                        <h4>Infrastructure as Code</h4>
                        <ul>
                            <li><strong>Terraform Modules:</strong> VPC with public/private subnets across 2 AZs, EKS
                                cluster with managed node groups (t3.small), EC2 instances, ECR repositories, IAM roles
                                and policies</li>
                            <li><strong>One-Click Deployment:</strong> Automated scripts handle Terraform
                                initialization, ECR imports, image verification, and full infrastructure provisioning
                            </li>
                            <li><strong>CI/CD Pipeline:</strong> GitHub Actions for automated Docker builds, AWS
                                authentication, and ECR pushes</li>
                        </ul>

                        <h4>Key Technical Achievements</h4>
                        <ul>
                            <li><strong>Cold Start Solution:</strong> Implemented exponential backoff retry—first
                                request warms Lambda (loads model), automatic retry succeeds. Achieved 100% success rate
                                despite timeout limitations.</li>
                            <li><strong>Secure ECR Access:</strong> IAM Instance Profiles with
                                <code>AmazonEC2ContainerRegistryReadOnly</code> policy—no credentials stored on disk
                            </li>
                            <li><strong>Async Resource Handling:</strong> Proper Terraform state management for
                                Kubernetes LoadBalancer provisioning (2-5 min delay)</li>
                            <li><strong>Comprehensive Testing:</strong> pytest with mocks, integration tests, Locust
                                load testing, custom benchmarking (P50, P95), and AI-powered SRE reports</li>
                        </ul>

                        <h4>Results & Impact</h4>
                        <ul>
                            <li><strong>Deployment Time:</strong> Reduced from manual 2+ hours to automated 15 minutes
                            </li>
                            <li><strong>Infrastructure Reliability:</strong> 100% reproducible deployments via Terraform
                            </li>
                            <li><strong>Code Quality:</strong> 90%+ test coverage with unit, integration, and load tests
                            </li>
                            <li><strong>Cost Analysis:</strong> Quantified cost trade-offs between serverless and
                                containerized approaches</li>
                        </ul>

                        <h4>Skills Demonstrated</h4>
                        <p><strong>Cloud & DevOps:</strong> AWS (Lambda, EKS, EC2, ECR, API Gateway, VPC, IAM),
                            Terraform, Kubernetes, Docker, GitHub Actions CI/CD</p>
                        <p><strong>Backend:</strong> FastAPI, Python, Prometheus metrics, exponential backoff patterns,
                            microservices architecture</p>
                        <p><strong>Testing:</strong> pytest, Locust load testing, Groq API integration for automated
                            analysis</p>
                    </div>
                </article>

                <!-- AI/ML Project: Audio RAG -->
                <article class="project-card" data-category="ai">
                    <div class="project-header">
                        <div class="project-icon">
                            <i class="fas fa-microphone"></i>
                        </div>
                        <div class="project-links-top">
                            <a href="https://github.com/Nirajan17/Audio-RAG" target="_blank" aria-label="GitHub">
                                <i class="fab fa-github"></i>
                            </a>
                        </div>
                    </div>
                    <h3 class="project-title">Audio RAG Assistant</h3>
                    <p class="project-description">
                        Transcribes audio with OpenAI Whisper and enables intelligent Q&A using Retrieval-Augmented
                        Generation.
                    </p>
                    <div class="project-tech">
                        <span>Whisper</span>
                        <span>RAG</span>
                        <span>Python</span>
                    </div>
                </article>

                <!-- AI/ML Project: digitalME -->
                <article class="project-card" data-category="ai">
                    <div class="project-header">
                        <div class="project-icon">
                            <i class="fas fa-robot"></i>
                        </div>
                        <div class="project-links-top">
                            <a href="https://github.com/Nirajan17/digitalME--Personal-Chatbot" target="_blank"
                                aria-label="GitHub">
                                <i class="fab fa-github"></i>
                            </a>
                        </div>
                    </div>
                    <h3 class="project-title">digitalME Personal Assistant</h3>
                    <p class="project-description">
                        Personal AI chatbot for natural conversations, document retrieval, and database queries.
                    </p>
                    <div class="project-tech">
                        <span>Python</span>
                        <span>NLP</span>
                        <span>RAG</span>
                    </div>
                </article>

                <!-- AI/ML Project: PDF Chat -->
                <article class="project-card" data-category="ai">
                    <div class="project-header">
                        <div class="project-icon">
                            <i class="fas fa-file-pdf"></i>
                        </div>
                        <div class="project-links-top">
                            <a href="https://github.com/Nirajan17/PDF-Chat-Assistant" target="_blank"
                                aria-label="GitHub">
                                <i class="fab fa-github"></i>
                            </a>
                        </div>
                    </div>
                    <h3 class="project-title">PDF Chat Assistant</h3>
                    <p class="project-description">
                        Upload PDFs and chat with them using Mistral-7B-Instruct for natural language document
                        interaction.
                    </p>
                    <div class="project-tech">
                        <span>Mistral</span>
                        <span>LLM</span>
                        <span>Python</span>
                    </div>
                </article>

                <!-- AI/ML Project: Nepali Captioning -->
                <article class="project-card" data-category="ai">
                    <div class="project-header">
                        <div class="project-icon">
                            <i class="fas fa-image"></i>
                        </div>
                        <div class="project-links-top">
                            <a href="https://github.com/paudelnirajan/Major_Project_image_captioning" target="_blank"
                                aria-label="GitHub">
                                <i class="fab fa-github"></i>
                            </a>
                        </div>
                    </div>
                    <h3 class="project-title">Nepali Image Captioning</h3>
                    <p class="project-description">
                        Transformer-based model generating paragraph-length Nepali captions with Inception V3 feature
                        extraction.
                    </p>
                    <div class="project-tech">
                        <span>Transformer</span>
                        <span>CNN</span>
                        <span>NLP</span>
                    </div>
                </article>

                <!-- Other: Tour Recommender -->
                <article class="project-card" data-category="ai">
                    <div class="project-header">
                        <div class="project-icon">
                            <i class="fas fa-map-marker-alt"></i>
                        </div>
                        <div class="project-links-top">
                            <a href="https://github.com/Nirajan17/Tour-Recommender-Pokhara" target="_blank"
                                aria-label="GitHub">
                                <i class="fab fa-github"></i>
                            </a>
                        </div>
                    </div>
                    <h3 class="project-title">Tour Recommender - Pokhara</h3>
                    <p class="project-description">
                        Content-based recommendation system for Pokhara destinations using descriptions, genres, and
                        keywords.
                    </p>
                    <div class="project-tech">
                        <span>Python</span>
                        <span>ML</span>
                        <span>NLP</span>
                    </div>
                </article>

                <!-- Cloud Project: Music Separation as a Service -->
                <article class="project-card" data-category="cloud">
                    <div class="project-header">
                        <div class="project-icon">
                            <i class="fas fa-music"></i>
                        </div>
                        <div class="project-links-top">
                            <a href="#" target="_blank" aria-label="GitHub">
                                <i class="fab fa-github"></i>
                            </a>
                        </div>
                    </div>
                    <h3 class="project-title">Music Separation as a Service</h3>
                    <p class="project-description">
                        Scalable microservices on GKE for AI-driven music source separation. Processes MP3s into 4
                        instrumental stems with async pipeline.
                    </p>
                    <div class="project-tech">
                        <span>GKE</span>
                        <span>Redis</span>
                        <span>Flask</span>
                        <span>Demucs</span>
                    </div>
                    <button class="project-expand" aria-label="Expand details">
                        <span>Details</span>
                        <i class="fas fa-arrow-right"></i>
                    </button>
                    <div class="project-details">
                        <h4>Overview</h4>
                        <p>The system processes user-uploaded MP3s through an asynchronous pipeline, separating them
                            into four distinct instrumental stems (vocals, drums, bass, other) for download.</p>

                        <h4>Key Achievements</h4>
                        <ul>
                            <li><strong>Infrastructure Migration:</strong> Spearheaded critical migration from
                                self-hosted MinIO to Google Cloud Storage (GCS), boosting data durability from ephemeral
                                state to <strong>99.99%</strong>. Eliminated single point of failure and reduced
                                operational overhead.</li>
                            <li><strong>Asynchronous Processing:</strong> Engineered async processing queue using Redis,
                                decoupling lightweight Flask REST API from resource-intensive ML worker. Reduced API
                                response time to <strong>under 200ms</strong> while handling ML inference tasks
                                averaging <strong>2-5 minutes per song</strong>.</li>
                            <li><strong>Scalability & Cost-Efficiency:</strong> Designed worker pool for horizontal
                                scaling on GKE. Architecture capable of processing hundreds of songs per hour by
                                dynamically adjusting worker pod replicas based on queue depth.</li>
                            <li><strong>Resource Management:</strong> Implemented precise Kubernetes resource requests
                                and limits (<strong>6Gi RAM</strong> for Demucs worker pods). Prevented pod evictions
                                from memory spikes and ensured predictable performance.</li>
                            <li><strong>Real-time Frontend:</strong> Developed dynamic frontend with JavaScript
                                providing real-time job status updates. UI transitions from upload → processing →
                                download links seamlessly.</li>
                        </ul>

                        <h4>Skills Demonstrated</h4>
                        <p><strong>Cloud:</strong> Google Kubernetes Engine (GKE), Google Cloud Storage, container
                            orchestration</p>
                        <p><strong>Backend:</strong> Flask, Redis, asynchronous processing, microservices architecture
                        </p>
                        <p><strong>ML/AI:</strong> Demucs model deployment, resource optimization for ML workloads</p>
                    </div>
                </article>
            </div>
        </section>

        <!-- Skills Section -->
        <section id="skills" class="section">
            <div class="section-header">
                <h2 class="section-title">
                    <span class="code-accent">//</span> Skills & Courses
                </h2>
                <div class="section-line"></div>
            </div>
            <div class="skills-content">
                <div class="skills-category">
                    <h3><i class="fas fa-terminal"></i> Languages</h3>
                    <div class="skill-tags">
                        <span class="skill-tag">Python</span>
                        <span class="skill-tag">C++</span>
                        <span class="skill-tag">C</span>
                        <span class="skill-tag">SQL</span>
                        <span class="skill-tag">Java</span>
                    </div>
                </div>
                <div class="skills-category">
                    <h3><i class="fas fa-brain"></i> AI & ML</h3>
                    <div class="skill-tags">
                        <span class="skill-tag">TensorFlow</span>
                        <span class="skill-tag">PyTorch</span>
                        <span class="skill-tag">LangChain/Langgraph</span>
                        <span class="skill-tag">Scikit-learn</span>
                        <span class="skill-tag">Transformers</span>
                        <span class="skill-tag">CNNs</span>
                        <span class="skill-tag">RNNs</span>
                    </div>
                </div>
                <div class="skills-category">
                    <h3><i class="fas fa-cloud"></i> Cloud & DevOps</h3>
                    <div class="skill-tags">
                        <span class="skill-tag">AWS</span>
                        <span class="skill-tag">GCP</span>
                        <span class="skill-tag">Kubernetes</span>
                        <span class="skill-tag">Docker</span>
                        <span class="skill-tag">Terraform</span>
                        <span class="skill-tag">GitHub Actions</span>
                    </div>
                </div>
                <div class="skills-category">
                    <h3><i class="fas fa-tools"></i> Tools & Frameworks</h3>
                    <div class="skill-tags">
                        <span class="skill-tag">FastAPI</span>
                        <span class="skill-tag">Flask</span>
                        <span class="skill-tag">Django</span>
                        <span class="skill-tag">Git</span>
                        <span class="skill-tag">Pandas</span>
                        <span class="skill-tag">NumPy</span>
                    </div>
                </div>
                <div class="courses-section">
                    <h3><i class="fas fa-book"></i> Graduate Coursework</h3>
                    <div class="course-list">
                        <div class="course-item">
                            <span class="course-code">CSCI 5253</span>
                            <span class="course-name">Data Center Scale Computing</span>
                        </div>
                        <div class="course-item">
                            <span class="course-code">CSCI 5448</span>
                            <span class="course-name">Object Oriented Analysis and Design</span>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!-- Publications Section -->
        <section id="publications" class="section">
            <div class="section-header">
                <h2 class="section-title">
                    <span class="code-accent">//</span> Publications
                </h2>
                <div class="section-line"></div>
            </div>
            <div class="publications-list">
                <article class="publication-card">
                    <div class="publication-year">2024</div>
                    <div class="publication-content">
                        <h3>
                            <a href="https://doi.org/10.36548/jismac.2024.1.005" target="_blank">
                                Drowsiness and Crash Detection Mobile Application for Vehicle's Safety
                                <i class="fas fa-external-link-alt"></i>
                            </a>
                        </h3>
                        <p class="publication-authors">
                            Subedi, Nabaraj, <strong>Nirajan Paudel</strong>, Manish Chhetri, Sudarshan Acharya, and
                            Nabin Lamichhane
                        </p>
                        <p class="publication-venue">
                            Journal of IoT in Social, Mobile, Analytics, and Cloud 6.1, pp. 54–66
                        </p>
                    </div>
                </article>
                <article class="publication-card">
                    <div class="publication-year">2024</div>
                    <div class="publication-content">
                        <h3>
                            <a href="https://doi.org/10.36548/jscp.2024.1.006" target="_blank">
                                Nepali Image Captioning: Generating Coherent Paragraph-Length Descriptions Using
                                Transformer
                                <i class="fas fa-external-link-alt"></i>
                            </a>
                        </h3>
                        <p class="publication-authors">
                            Subedi, Nabaraj, <strong>Nirajan Paudel</strong>, Manish Chhetri, Sudarshan Acharya, and
                            Nabin Lamichhane
                        </p>
                        <p class="publication-venue">
                            Journal of Soft Computing Paradigm 6.1, pp. 70–84
                        </p>
                    </div>
                </article>
            </div>
        </section>

        <!-- Blog Section -->
        <!-- Blog Section -->
        <section id="blog" class="section">
            <div class="section-header">
                <h2 class="section-title">
                    <span class="code-accent">//</span> Blog
                </h2>
                <div class="section-line"></div>
            </div>
            <div class="blog-grid" id="blog-grid">
                <!-- Blog posts will be dynamically inserted here by script.js -->
            </div>
        </section>

        <!-- Footer -->
        <footer class="footer">
            <div class="footer-content">
                <p class="footer-text">
                    <span class="code-accent">&lt;</span>
                    Envisioned & Prompted by Nirajan Paudel
                    <span class="code-accent">/&gt;</span>
                </p>
                <div class="footer-links">
                    <a href="mailto:nirajan.paudel@colorado.edu" aria-label="Email"><i class="fas fa-envelope"></i></a>
                    <a href="https://www.linkedin.com/in/nirajanpaudel17/" target="_blank" aria-label="LinkedIn"><i
                            class="fab fa-linkedin"></i></a>
                    <a href="https://github.com/paudelnirajan" target="_blank" aria-label="GitHub"><i
                            class="fab fa-github"></i></a>
                    <a href="https://x.com/paudelnirajan17" target="_blank" aria-label="Twitter"><i
                            class="fab fa-twitter"></i></a>
                </div>
            </div>
        </footer>
    </div>

    <!-- Project Modal -->
    <div id="project-modal" class="modal">
        <div class="modal-content">
            <button class="modal-close" aria-label="Close modal">&times;</button>
            <div id="modal-body"></div>
        </div>
    </div>

    <script src="blog-data.js"></script>
    <script src="script.js"></script>
</body>

</html>